# -*- coding: utf-8 -*-
"""appcar1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RBnhFHxv9_kUhqpSGDEe4aNnsTtSforq
"""

import pandas as pd

# Load dataset


# View basic info
print(df.shape)
print(df.info())
print(df.isnull().sum())
# If missing values exist, handle with mode imputation (categorical data)
df.fillna(df.mode().iloc[0], inplace=True)

# Convert categorical to numeric using LabelEncoder
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
for col in df.columns:
    df[col] = le.fit_transform(df[col])
# Confirm class distribution
print(df['class'].value_counts())
import seaborn as sns
import matplotlib.pyplot as plt

# Correlation heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()

# Target vs Features
for col in df.columns[:-1]:
    sns.countplot(x=col, hue='class', data=df)
    plt.title(f'{col} vs Class')
    plt.show()
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# Split data
X = df.drop('class', axis=1)
y = df['class']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model
model = RandomForestClassifier()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Evaluate
print(classification_report(y_test, y_pred))
importances = model.feature_importances_
feature_names = X.columns
sorted_importance = sorted(zip(importances, feature_names), reverse=True)
print(sorted_importance)
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import f1_score

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "KNN": KNeighborsClassifier(),
    "Random Forest": RandomForestClassifier(),
    "Decision Tree": DecisionTreeClassifier()
}

for name, clf in models.items():
    clf.fit(X_train, y_train)
    preds = clf.predict(X_test)
    f1 = f1_score(y_test, preds, average='weighted')
    print(f"{name}: F1 Score = {f1:.4f}")
import streamlit as st
import pandas as pd
import joblib

model = joblib.load('best_model.pkl')

st.title("Car Evaluation Predictor")

inputs = {}
for feature in ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety']:
    inputs[feature] = st.selectbox(f"Select {feature}", ['low', 'med', 'high', 'vhigh'])

# Convert to DataFrame & preprocess
input_df = pd.DataFrame([inputs])
# Encode similarly to training
for col in input_df.columns:
    input_df[col] = LabelEncoder().fit_transform(input_df[col])

if st.button("Predict"):
    prediction = model.predict(input_df)
    st.success(f"Predicted Class: {prediction[0]}")
